"""
Seedream 4.0 MCPå·¥å…· - ç»„å›¾ç”Ÿæˆå·¥å…·

å®ç°è¿ç»­ç”Ÿæˆå¤šå¼ å›¾åƒåŠŸèƒ½ï¼Œæ”¯æŒè‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°ã€‚
"""

from typing import Any, Dict, List, Optional
from pathlib import Path
from mcp.types import Tool, TextContent

from ..client import SeedreamClient
from ..config import SeedreamConfig, get_global_config
from ..utils.logging import get_logger
from ..utils.auto_save import AutoSaveManager, AutoSaveResult


# å·¥å…·å®šä¹‰
sequential_generation_tool = Tool(
    name="seedream_sequential_generation",
    description="ä½¿ç”¨Seedream 4.0è¿ç»­ç”Ÿæˆå¤šå¼ å›¾åƒï¼ˆç»„å›¾ç”Ÿæˆï¼‰ï¼Œæ”¯æŒ3ç§è¾“å…¥ç±»å‹ï¼šæ–‡ç”Ÿç»„å›¾ã€å•å›¾ç”Ÿç»„å›¾ã€å¤šå›¾ç”Ÿç»„å›¾ï¼Œæ”¯æŒè‡ªåŠ¨ä¿å­˜åˆ°æœ¬åœ°",
    inputSchema={
        "type": "object",
        "properties": {
            "prompt": {
                "type": "string",
                "description": "å›¾åƒç”Ÿæˆçš„æ–‡æœ¬æç¤ºè¯ï¼Œå»ºè®®ä¸è¶…è¿‡600ä¸ªå­—ç¬¦",
                "maxLength": 600
            },
            "max_images": {
                "type": "integer",
                "description": "æœ€å¤§ç”Ÿæˆå›¾åƒæ•°é‡",
                "minimum": 1,
                "maximum": 15,
                "default": 4
            },
            "size": {
                "type": "string",
                "description": "ç”Ÿæˆå›¾åƒçš„å°ºå¯¸ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼",
                "enum": ["1K", "2K", "4K"]
            },
            "watermark": {
                "type": "boolean",
                "description": "æ˜¯å¦åœ¨ç”Ÿæˆçš„å›¾åƒä¸Šæ·»åŠ æ°´å°ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼"
            },
            "response_format": {
                "type": "string",
                "description": "å“åº”æ ¼å¼ï¼šurlè¿”å›å›¾åƒURLï¼Œb64_jsonè¿”å›base64ç¼–ç ",
                "enum": ["url", "b64_json"],
                "default": "url"
            },
            "image": {
                "type": ["string", "array"],
                "description": "å¯é€‰çš„å‚è€ƒå›¾åƒã€‚æ”¯æŒå•å¼ å›¾ç‰‡URL/è·¯å¾„ï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–å¤šå¼ å›¾ç‰‡URL/è·¯å¾„ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰ã€‚ç”¨äºå•å›¾ç”Ÿç»„å›¾æˆ–å¤šå›¾ç”Ÿç»„å›¾",
                "items": {
                    "type": "string"
                },
                "maxItems": 10
            },
            "auto_save": {
                "type": "boolean",
                "description": "æ˜¯å¦è‡ªåŠ¨ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡åˆ°æœ¬åœ°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨å…¨å±€é…ç½®",
                "default": None
            },
            "save_path": {
                "type": "string",
                "description": "è‡ªå®šä¹‰ä¿å­˜ç›®å½•è·¯å¾„ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®è·¯å¾„"
            },
            "custom_name": {
                "type": "string",
                "description": "è‡ªå®šä¹‰æ–‡ä»¶åå‰ç¼€ã€‚å¦‚æœæœªæŒ‡å®šï¼Œå°†æ ¹æ®æç¤ºè¯è‡ªåŠ¨ç”Ÿæˆ"
            }
        },
        "required": ["prompt"]
    }
)


async def handle_sequential_generation(arguments: Dict[str, Any]) -> List[TextContent]:
    """å¤„ç†ç»„å›¾ç”Ÿæˆè¯·æ±‚
    
    Args:
        arguments: å·¥å…·å‚æ•°
        
    Returns:
        MCPå“åº”å†…å®¹
    """
    logger = get_logger(__name__)
    
    try:
        # è·å–é…ç½®
        config = get_global_config()
        
        # æå–å‚æ•°ï¼ŒæŒ‰ä¼˜å…ˆçº§ï¼šè°ƒç”¨å‚æ•° > é…ç½®æ–‡ä»¶é»˜è®¤å€¼ > æ–¹æ³•é»˜è®¤å€¼
        prompt = arguments.get("prompt")
        max_images = arguments.get("max_images", 4)
        size = arguments.get("size") or config.default_size
        watermark = arguments.get("watermark")
        if watermark is None:
            watermark = config.default_watermark
        response_format = arguments.get("response_format", "url")
        image = arguments.get("image")
        
        # æå–è‡ªåŠ¨ä¿å­˜å‚æ•°
        auto_save = arguments.get("auto_save")
        save_path = arguments.get("save_path")
        custom_name = arguments.get("custom_name")
        
        # éªŒè¯å‚æ•°
        if not prompt:
            return [TextContent(type="text", text="é”™è¯¯ï¼špromptå‚æ•°æ˜¯å¿…éœ€çš„")]
        
        if max_images < 1 or max_images > 15:
            return [TextContent(type="text", text="é”™è¯¯ï¼šmax_imageså¿…é¡»åœ¨1-15ä¹‹é—´")]
        
        if size not in ["1K", "2K", "4K"]:
            return [TextContent(type="text", text="é”™è¯¯ï¼šsizeå¿…é¡»æ˜¯1Kã€2Kæˆ–4K")]
        
        if response_format not in ["url", "b64_json"]:
            return [TextContent(type="text", text="é”™è¯¯ï¼šresponse_formatå¿…é¡»æ˜¯urlæˆ–b64_json")]
        
        # éªŒè¯imageå‚æ•°
        if image is not None:
            if isinstance(image, str):
                # å•å¼ å›¾ç‰‡
                if not image.strip():
                    return [TextContent(type="text", text="é”™è¯¯ï¼šimageå‚æ•°ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²")]
            elif isinstance(image, list):
                # å¤šå¼ å›¾ç‰‡
                if len(image) == 0:
                    return [TextContent(type="text", text="é”™è¯¯ï¼šimageæ•°ç»„ä¸èƒ½ä¸ºç©º")]
                if len(image) > 10:
                    return [TextContent(type="text", text="é”™è¯¯ï¼šæœ€å¤šæ”¯æŒ10å¼ å‚è€ƒå›¾ç‰‡")]
                for img in image:
                    if not isinstance(img, str) or not img.strip():
                        return [TextContent(type="text", text="é”™è¯¯ï¼šimageæ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")]
            else:
                return [TextContent(type="text", text="é”™è¯¯ï¼šimageå‚æ•°å¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²æ•°ç»„")]
        
        logger.info(f"å¼€å§‹å¤„ç†ç»„å›¾ç”Ÿæˆè¯·æ±‚: prompt='{prompt[:50]}...', max_images={max_images}, size={size}")
        
        # ç¡®å®šæ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¿å­˜
        enable_auto_save = auto_save if auto_save is not None else config.auto_save_enabled
        
        # åˆ›å»ºå®¢æˆ·ç«¯å¹¶è°ƒç”¨API
        async with SeedreamClient(config) as client:
            result = await client.sequential_generation(
                prompt=prompt,
                max_images=max_images,
                size=size,
                watermark=watermark,
                response_format=response_format,
                image=image
            )
        
        # åˆå§‹åŒ–è‡ªåŠ¨ä¿å­˜ç»“æœ
        auto_save_results = []
        
        # å¦‚æœå¯ç”¨è‡ªåŠ¨ä¿å­˜ä¸”APIè°ƒç”¨æˆåŠŸï¼Œæ‰§è¡Œè‡ªåŠ¨ä¿å­˜
        if enable_auto_save and result.get("success"):
            try:
                if response_format == "url":
                    auto_save_results = await _handle_auto_save(
                        result, prompt, config, save_path, custom_name
                    )
                    if auto_save_results:
                        result = _update_result_with_auto_save(result, auto_save_results)
                elif response_format == "b64_json":
                    auto_save_results = await _handle_auto_save_base64(
                        result, prompt, config, save_path, custom_name
                    )
                    if auto_save_results:
                        result = _update_result_with_auto_save(result, auto_save_results)
            except Exception as e:
                logger.warning(f"è‡ªåŠ¨ä¿å­˜å¤±è´¥ï¼Œä½†ç»§ç»­è¿”å›åŸå§‹ç»“æœ: {e}")
        
        # æ ¼å¼åŒ–å“åº”
        response_text = _format_sequential_generation_response(
            result, prompt, max_images, size, auto_save_results, enable_auto_save
        )
        
        logger.info("ç»„å›¾ç”Ÿæˆè¯·æ±‚å¤„ç†å®Œæˆ")
        return [TextContent(type="text", text=response_text)]
        
    except Exception as e:
        logger.error(f"ç»„å›¾ç”Ÿæˆè¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}")
        error_msg = f"ç»„å›¾ç”Ÿæˆå¤±è´¥: {str(e)}"
        return [TextContent(type="text", text=error_msg)]


async def _handle_auto_save(
    result: Dict[str, Any],
    prompt: str,
    config: SeedreamConfig,
    save_path: Optional[str] = None,
    custom_name: Optional[str] = None
) -> List[AutoSaveResult]:
    """å¤„ç†è‡ªåŠ¨ä¿å­˜é€»è¾‘
    
    Args:
        result: APIå“åº”ç»“æœ
        prompt: ç”Ÿæˆæç¤ºè¯
        config: é…ç½®å¯¹è±¡
        save_path: è‡ªå®šä¹‰ä¿å­˜è·¯å¾„
        custom_name: è‡ªå®šä¹‰æ–‡ä»¶åå‰ç¼€
        
    Returns:
        è‡ªåŠ¨ä¿å­˜ç»“æœåˆ—è¡¨
    """
    # åˆå§‹åŒ–è‡ªåŠ¨ä¿å­˜ç®¡ç†å™¨
    base_dir = Path(save_path) if save_path else (
        Path(config.auto_save_base_dir) if config.auto_save_base_dir else None
    )
    
    auto_save_manager = AutoSaveManager(
        base_dir=base_dir,
        download_timeout=config.auto_save_download_timeout,
        max_retries=config.auto_save_max_retries,
        max_file_size=config.auto_save_max_file_size,
        max_concurrent=config.auto_save_max_concurrent
    )
    
    # æå–å›¾ç‰‡URL
    image_urls = []
    if result.get("data"):
        for item in result["data"]:
            if item.get("url"):
                image_urls.append(item["url"])
    
    if not image_urls:
        return []
    
    # å‡†å¤‡å›¾ç‰‡æ•°æ®
    image_data = []
    for i, url in enumerate(image_urls):
        data = {
            "url": url,
            "prompt": prompt,
            "custom_name": custom_name
        }
        image_data.append(data)
    
    # æ‰§è¡Œæ‰¹é‡ä¿å­˜
    return await auto_save_manager.save_multiple_images(
        image_data, "sequential_generation"
    )


async def _handle_auto_save_base64(
    result: Dict[str, Any],
    prompt: str,
    config: SeedreamConfig,
    save_path: Optional[str] = None,
    custom_name: Optional[str] = None
) -> List[AutoSaveResult]:
    """å¤„ç† base64 è‡ªåŠ¨ä¿å­˜ï¼ˆç»„å›¾ç”Ÿæˆï¼‰
    å½“ response_format ä¸º b64_json æ—¶ï¼Œä»ç»“æœä¸­æå– base64 å¹¶ä¿å­˜åˆ°æœ¬åœ°ã€‚
    """
    logger = get_logger(__name__)
    try:
        base_dir = Path(save_path) if save_path else (
            Path(config.auto_save_base_dir) if config.auto_save_base_dir else None
        )

        auto_save_manager = AutoSaveManager(
            base_dir=base_dir,
            download_timeout=config.auto_save_download_timeout,
            max_retries=config.auto_save_max_retries,
            max_file_size=config.auto_save_max_file_size,
            max_concurrent=config.auto_save_max_concurrent
        )

        data = result.get("data", {})
        if isinstance(data, list):
            images = data
        elif isinstance(data, dict) and "data" in data:
            images = data["data"]
        else:
            images = [data]

        image_data = []
        for i, image in enumerate(images):
            if isinstance(image, dict) and "b64_json" in image:
                image_data.append({
                    'b64_json': image['b64_json'],
                    'prompt': prompt,
                    'custom_name': f"{custom_name}_{i+1}" if custom_name else None,
                    'alt_text': f"Generated image {i+1}: {prompt[:50]}..."
                })

        if not image_data:
            logger.warning("æœªæ‰¾åˆ°å¯ä¿å­˜çš„Base64å›¾ç‰‡æ•°æ®")
            return []

        auto_save_results = await auto_save_manager.save_multiple_base64_images(
            image_data, tool_name="sequential_generation"
        )
        logger.info(f"Base64 è‡ªåŠ¨ä¿å­˜å®Œæˆ: {len(auto_save_results)} ä¸ªå›¾ç‰‡")
        return auto_save_results
    except Exception as e:
        logger.error(f"Base64 è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}")
        return []


def _update_result_with_auto_save(
    result: Dict[str, Any],
    auto_save_results: List[AutoSaveResult]
) -> Dict[str, Any]:
    """æ›´æ–°ç»“æœä»¥åŒ…å«è‡ªåŠ¨ä¿å­˜ä¿¡æ¯
    
    Args:
        result: åŸå§‹APIç»“æœ
        auto_save_results: è‡ªåŠ¨ä¿å­˜ç»“æœåˆ—è¡¨
        
    Returns:
        æ›´æ–°åçš„ç»“æœ
    """
    # åˆ›å»ºç»“æœå‰¯æœ¬
    updated_result = result.copy()
    
    # ç»Ÿè®¡ä¿å­˜ç»“æœ
    successful_saves = sum(1 for r in auto_save_results if r.success)
    failed_saves = len(auto_save_results) - successful_saves
    
    # æ·»åŠ è‡ªåŠ¨ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    updated_result["auto_save_summary"] = {
        "total": len(auto_save_results),
        "successful": successful_saves,
        "failed": failed_saves
    }
    
    # ä¸ºæˆåŠŸä¿å­˜çš„å›¾ç‰‡æ·»åŠ æœ¬åœ°è·¯å¾„ä¿¡æ¯
    if updated_result.get("data") and auto_save_results:
        for i, (item, save_result) in enumerate(zip(updated_result["data"], auto_save_results)):
            if save_result.success:
                item["local_path"] = str(save_result.local_path)
                item["markdown_ref"] = save_result.markdown_ref
    
    return updated_result


def _format_sequential_generation_response(
    result: Dict[str, Any], 
    prompt: str, 
    max_images: int, 
    size: str,
    auto_save_results: Optional[List[AutoSaveResult]] = None,
    auto_save_enabled: bool = False
) -> str:
    """æ ¼å¼åŒ–ç»„å›¾ç”Ÿæˆå“åº”
    
    Args:
        result: APIå“åº”ç»“æœ
        prompt: åŸå§‹æç¤ºè¯
        max_images: æœ€å¤§å›¾åƒæ•°é‡
        size: å›¾åƒå°ºå¯¸
        
    Returns:
        æ ¼å¼åŒ–çš„å“åº”æ–‡æœ¬
    """
    if not result.get("success"):
        return f"å›¾åƒç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
    
    data = result.get("data", {})
    usage = result.get("usage", {})
    
    # æ„å»ºå“åº”æ–‡æœ¬
    response_lines = [
        "âœ… ç»„å›¾ç”Ÿæˆä»»åŠ¡å®Œæˆ",
        "",
        f"ğŸ“ æç¤ºè¯: {prompt}",
        f"ğŸ”¢ è¯·æ±‚ç”Ÿæˆæ•°é‡: {max_images}å¼ ",
        f"ğŸ“ å°ºå¯¸: {size}",
        ""
    ]
    
    # å¤„ç†ç”Ÿæˆçš„å›¾åƒ
    if isinstance(data, list):
        images = data
    elif isinstance(data, dict) and "data" in data:
        images = data["data"]
    else:
        images = [data]
    
    if images:
        actual_count = len(images)
        response_lines.append(f"ğŸ¨ å®é™…ç”Ÿæˆå›¾åƒ: {actual_count}å¼ ")
        response_lines.append("")
        
        for i, image in enumerate(images, 1):
            response_lines.append(f"ğŸ“· å›¾åƒ {i}:")
            if isinstance(image, dict):
                # URLä¿¡æ¯ï¼ˆå¦‚å­˜åœ¨ï¼‰
                if "url" in image:
                    response_lines.append(f"  â€¢ URL: {image['url']}")
                
                # Base64ä¿¡æ¯ï¼ˆå¦‚å­˜åœ¨ï¼‰
                if "b64_json" in image:
                    response_lines.append(f"  â€¢ æ•°æ®: [Base64ç¼–ç ï¼Œé•¿åº¦: {len(image['b64_json'])}å­—ç¬¦]")
                
                # è‡ªåŠ¨ä¿å­˜åçš„æœ¬åœ°è·¯å¾„ä¸å¼•ç”¨ï¼ˆå¦‚å­˜åœ¨ï¼‰
                if "local_path" in image:
                    response_lines.append(f"  â€¢ ğŸ’¾ æœ¬åœ°è·¯å¾„: {image['local_path']}")
                if "markdown_ref" in image:
                    response_lines.append(f"  â€¢ ğŸ“ Markdownå¼•ç”¨: {image['markdown_ref']}")
                
                # ä¿®è®¢æç¤ºè¯ï¼ˆå¦‚å­˜åœ¨ï¼‰
                if "revised_prompt" in image:
                    response_lines.append(f"  â€¢ ä¿®è®¢æç¤ºè¯: {image['revised_prompt']}")
            else:
                response_lines.append(f"  â€¢ {str(image)}")
            response_lines.append("")
        
        # ç”Ÿæˆæ•°é‡ç»Ÿè®¡
        if actual_count != max_images:
            response_lines.append(f"â„¹ï¸ æ³¨æ„: è¯·æ±‚ç”Ÿæˆ{max_images}å¼ ï¼Œå®é™…ç”Ÿæˆ{actual_count}å¼ ")
            response_lines.append("")
    
    # æ·»åŠ ä½¿ç”¨ç»Ÿè®¡
    if usage:
        response_lines.extend([
            "ğŸ“Š ä½¿ç”¨ç»Ÿè®¡:"
        ])
        if "prompt_tokens" in usage:
            response_lines.append(f"  â€¢ æç¤ºè¯ä»¤ç‰Œæ•°: {usage['prompt_tokens']}")
        if "total_tokens" in usage:
            response_lines.append(f"  â€¢ æ€»ä»¤ç‰Œæ•°: {usage['total_tokens']}")
        if "cost" in usage:
            response_lines.append(f"  â€¢ è´¹ç”¨: {usage['cost']}")
        response_lines.append("")
    
    # æ·»åŠ è‡ªåŠ¨ä¿å­˜æ‘˜è¦ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if auto_save_enabled and auto_save_results:
        successful_saves = sum(1 for r in auto_save_results if r.success)
        failed_saves = len(auto_save_results) - successful_saves
        
        response_lines.extend([
            "",
            "ğŸ’¾ è‡ªåŠ¨ä¿å­˜æ‘˜è¦:",
            f"  â€¢ æ€»è®¡: {len(auto_save_results)}å¼ å›¾ç‰‡",
            f"  â€¢ æˆåŠŸ: {successful_saves}å¼ ",
            f"  â€¢ å¤±è´¥: {failed_saves}å¼ "
        ])
    
    # æ·»åŠ ç»„å›¾ç”Ÿæˆè¯´æ˜
    response_lines.extend([
        "",
        "ğŸ’¡ ç»„å›¾ç”Ÿæˆè¯´æ˜:",
        "  â€¢ ç»„å›¾ç”Ÿæˆä¼šåŸºäºåŒä¸€ä¸ªæç¤ºè¯ç”Ÿæˆå¤šå¼ ä¸åŒçš„å›¾åƒ",
        "  â€¢ æ¯å¼ å›¾åƒéƒ½æ˜¯ç‹¬ç«‹ç”Ÿæˆçš„ï¼Œä¼šæœ‰ä¸åŒçš„è§†è§‰æ•ˆæœ",
        "  â€¢ é€‚ç”¨äºéœ€è¦å¤šä¸ªè®¾è®¡æ–¹æ¡ˆæˆ–åˆ›æ„é€‰æ‹©çš„åœºæ™¯",
        "  â€¢ å¯ä»¥ä»ç”Ÿæˆçš„å¤šå¼ å›¾åƒä¸­é€‰æ‹©æœ€æ»¡æ„çš„ç»“æœ"
    ])
    
    return "\n".join(response_lines)
